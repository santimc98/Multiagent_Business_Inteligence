# ğŸ” AUDITORÃA DEL REFACTORING DE CLAUDE CODE
## Basado en la AuditorÃ­a de Seniority de Agentes
**Fecha:** 2026-02-15  
**Auditor:** Antigravity (Gemini)  
**Trabajo auditado:** Refactoring de Claude Code en 12 fases

---

## ğŸ“Š RESUMEN EJECUTIVO

| Fase | RecomendaciÃ³n Original | Â¿Implementado? | Â¿Correcto? | Riesgo |
|---|---|---|---|---|
| **F1: Execution Planner - Token Sets** | Eliminar 7 token sets hardcodeados | âœ… SÃ­ | âš ï¸ Parcial | ğŸŸ¡ Medio |
| **F2: Failure Explainer - Fallback** | Eliminar 12 patrones hardcodeados | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |
| **F3: Cleaning Reviewer - Gates/regex** | Eliminar fallback gates y regex | âœ… SÃ­ | âš ï¸ Parcial | ğŸŸ¡ Medio |
| **F4: QA Reviewer - Keywords** | Eliminar _REGRESSOR_KEYWORDS | âœ… SÃ­ | âš ï¸ Parcial | ğŸŸ¡ Medio |
| **F6: Steward - Token sets** | Eliminar SPLIT/TEMPORAL tokens | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |
| **F7: domain_knowledge.py** | Eliminar archivo | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |
| **F8: Domain Expert - LLM-primary** | LLM reviews con prioridad | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |
| **F9: Import blocklist DE/ML** | Agregar SANDBOX SECURITY secciÃ³n | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |
| **F10: Review Board - Contexto hist.** | Iteration history + plateau | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |
| **F11: graph.py - MÃ³dulos extraÃ­dos** | Extraer funciones a steps/ | âš ï¸ Parcial | ğŸ”´ Incompleto | ğŸ”´ Alto |
| **F12: Retry loop mejorado** | _build_retry_context() | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |
| **Tests** | No romper tests existentes | âœ… SÃ­ | âœ… Correcto | ğŸŸ¢ Bajo |

**Veredicto global: 8 de 12 fases correctamente implementadas, 3 parciales, 1 incompleta con riesgo alto.**

---

## ğŸ“‹ ANÃLISIS DETALLADO POR FASE

---

### âœ… Fase 2: Failure Explainer â€” CORRECTO

**Lo que hizo Claude Code:**
- EliminÃ³ los 12 patrones if/elif hardcodeados del `_fallback()`.
- ReemplazÃ³ con: `f"Automated diagnosis unavailable. Raw error summary: {error_details[:500]}"`

**Veredicto:** âœ… **Bien hecho.** Exactamente lo que recomendÃ©. El fallback ahora pasa el error raw al downstream en vez de intentar diagnosticarlo con pattern matching. Los prompts LLM de `explain_data_engineer_failure` y `explain_ml_failure` se mantienen intactos y son la fuente primaria de diagnÃ³stico.

**Riesgo:** ğŸŸ¢ Bajo.

---

### âœ… Fase 6: Steward â€” CORRECTO

**Lo que hizo Claude Code:**
- EliminÃ³ `SPLIT_CANDIDATE_TOKENS` y `_TEMPORAL_HINT_TOKENS` como constantes globales.
- Las reemplazÃ³ con `_split_hints` y `_temporal_hints` como variables **locales** dentro de las funciones que las usan.
- AÃ±adiÃ³ detecciÃ³n dtype-based para temporales: `pd.api.types.is_datetime64_any_dtype(df[col])`.

**Veredicto:** âœ… **Correcto y bien razonado.** Las constantes globales se convirtieron en hints locales, y se aÃ±adiÃ³ detecciÃ³n por dtype como complemento. El comentario es preciso: "kept as minimal structural hints only for the evidence-layer profiling, not for classification decisions."

**Riesgo:** ğŸŸ¢ Bajo. Los tokens son idÃ©nticos pero ahora son locales, lo cual es mejor encapsulaciÃ³n. La detecciÃ³n por dtype es una mejora real.

---

### âœ… Fase 7: domain_knowledge.py eliminado â€” CORRECTO

**Lo que hizo Claude Code:**
- EliminÃ³ `src/utils/domain_knowledge.py`.
- RemoviÃ³ `from src.utils.domain_knowledge import infer_domain_guidance` del `domain_expert.py`.
- EliminÃ³ la llamada a `infer_domain_guidance()` y el parÃ¡metro `domain_guidance` del `_build_prompt()`.
- ActualizÃ³ el prompt section de `*** DOMAIN GUIDANCE ***` con instrucciones para que el LLM infiera domain knowledge:
  ```
  Infer domain-specific best practices and risks from the data context and business objective.
  Do not rely on pre-defined domain templates.
  ```

**Veredicto:** âœ… **Correcto.** La eliminaciÃ³n del archivo de conocimiento de dominio pre-definido es exactamente lo que recomendÃ©. El prompt ahora instruye al LLM a razonar sobre el dominio en vez de usar templates fijos.

**Riesgo:** ğŸŸ¢ Bajo.

---

### âœ… Fase 8: Domain Expert â€” LLM-primary scoring â€” CORRECTO

**Lo que hizo Claude Code:**
```python
# Antes: deterministic reviews tenÃ­an prioridad por defecto
merged: Dict[int, Dict] = {int(r["strategy_index"]): dict(r) for r in deterministic_reviews}
for item in normalized_llm:
    merged[idx] = item  # LLM sobreescribe

# Ahora: LLM tiene prioridad explÃ­cita
llm_by_idx = {idx: item for item in normalized_llm}  # LLM primero
det_by_idx = {int(r["strategy_index"]): dict(r) for r in deterministic_reviews}
# Usa LLM si existe, deterministic solo como safety net
if idx in llm_by_idx:
    base = llm_by_idx[idx]
elif idx in det_by_idx:
    base = det_by_idx[idx]
```

**Veredicto:** âœ… **Correcto.** El cambio de prioridad es sutil pero importante. Antes, el dict `merged` empezaba con deterministic y luego sobreescribÃ­a con LLM (lo cual tÃ©cnicamente tambiÃ©n daba prioridad al LLM, pero la intenciÃ³n no era clara). Ahora la prioridad es explÃ­cita y legible: LLM primero, deterministic solo como fallback.

**Riesgo:** ğŸŸ¢ Bajo.

---

### âœ… Fase 9: Import blocklist en DE/ML â€” CORRECTO

**Lo que hizo Claude Code:**
AgregÃ³ esta secciÃ³n idÃ©ntica en ambos prompts (DE y ML):
```
SANDBOX SECURITY - BLOCKED IMPORTS (HARD CONSTRAINT):
These imports are FORBIDDEN and will cause immediate script rejection:
- sys, subprocess, socket, requests, httpx, urllib, ftplib
- paramiko, selenium, playwright, openai, google.generativeai, builtins
- eval(), exec(), compile(), __import__()
ALLOWED imports: pandas, numpy, sklearn, scipy, xgboost, catboost, lightgbm,
matplotlib, seaborn, json, os.path, os.makedirs, csv, math, statistics,
collections, itertools, functools, typing, warnings, re, datetime, pathlib.Path
If you need sys.stdout or sys.exit, use print() and raise SystemExit instead.
```

**Veredicto:** âœ… **Excelente.** Esta es probablemente la mejora de mayor impacto inmediato â€” directamente aborda el root cause de la run fallida `ad3ee87d` donde tanto el DE como el ML generaron `import sys`. La lista de imports prohibidos es explÃ­cita, la allowlist es completa, y la alternativa para `sys` estÃ¡ documentada.

**Riesgo:** ğŸŸ¢ Bajo.

---

### âœ… Fase 10: Review Board â€” Contexto histÃ³rico â€” CORRECTO

**Lo que hizo Claude Code:**
1. AÃ±adiÃ³ instrucciones al prompt del Board:
   ```
   6) Use iteration_history when available to detect progress trends, plateaus, or regressions across iterations.
      If metrics have plateaued for 2+ iterations with no improvement, flag it in required_actions.
   ```
2. AÃ±adiÃ³ plateau detection en `_fallback()` (lÃ­neas 172-186): compara mÃ©tricas de las Ãºltimas 2 iteraciones.
3. En `graph.py`, `run_review_board` ahora construye `iteration_history` desde `metric_history` y lo pasa al `board_context`.

**Veredicto:** âœ… **Bien implementado.** La detecciÃ³n de plateau es simple pero efectiva (abs diff < 1e-6). El contexto histÃ³rico se limita a las Ãºltimas 10 iteraciones para no saturar el prompt.

**Riesgo:** ğŸŸ¢ Bajo.

---

### âœ… Fase 12: Retry loop mejorado â€” CORRECTO

**Lo que hizo Claude Code:**
CreÃ³ `_build_retry_context()` con clasificaciÃ³n estructurada de errores:
```python
{
    "error_type": "security_violation" | "runtime_error" | "output_missing" | "gate_failure" | "unknown",
    "specific_error": str,            # Error truncado a 500 chars
    "blocked_imports": List[str],     # Imports que causaron el rechazo
    "missing_outputs": List[str],     # Outputs que faltan
    "working_components": List[str],  # Lo que SÃ funcionÃ³
    "failed_gates": List[Dict],       # Gates que fallaron con evidencia
}
```

El `retry_context` se integra en `_build_iteration_handoff()` como campo adicional.

**Veredicto:** âœ… **Bien diseÃ±ado.** La clasificaciÃ³n de error types es crucial para que el ML/DE sepan exactamente quÃ© arreglar. El campo `working_components` previene el "Retry Amnesia" que identifiquÃ©. La extracciÃ³n de `blocked_imports` desde `last_safety_scan` es un buen detalle.

**Riesgo:** ğŸŸ¢ Bajo.

---

### âš ï¸ Fase 1: Execution Planner â€” Token Sets â€” PARCIAL

**Lo que hizo Claude Code:**
- EliminÃ³ 7 token sets globales (~120 tokens total).
- EliminÃ³ funciones helper: `_matches_any_phrase`, `_contains_decisioning_token`, `_contains_visual_token`.
- CreÃ³ `CAPABILITY_DETECTION_PROMPT` con instrucciones para detecciÃ³n semÃ¡ntica por LLM.
- InyectÃ³ el prompt en `CONTRACT_HARD_RULES`.

**âš ï¸ Problemas detectados:**

1. **`_strategy_mentions_resampling` reintroduce tokens inline:**
   ```python
   # Antes: return any(token in haystack for token in _RESAMPLING_TOKENS)
   # Ahora:
   return any(tok in haystack for tok in ("resamp", "cross valid", "cross-valid", "kfold", "k-fold", "bootstrap", "stratified"))
   ```
   Se eliminaron como constantes globales pero se reintrodujeron como tupla literal inline. Los tokens cambiaron ligeramente (usando prefijos como "resamp" en vez de "resampling" y "resample"), lo cual es mÃ¡s genÃ©rico, pero sigue siendo una lista hardcodeada.

2. **`_build_visual_requirements` reintroduce tokens inline:**
   ```python
   enabled = bool(vision_text and any(tok in vision_text.split() for tok in ("visual", "plot", "chart", "graph", "diagram", "figure")))
   ```
   Se eliminÃ³ `_VISUAL_ENABLED_TOKENS` (21 tokens) pero se reemplazÃ³ con una lista mÃ¡s corta de 6 tokens. Mejora parcial â€” la lista es mÃ¡s pequeÃ±a y genÃ©rica, pero sigue siendo keyword matching.

3. **`_build_decisioning_requirements` mantiene keyword matching:**
   ```python
   enabled = bool(existing_dec.get("enabled")) or any(
       kw in objective_type for kw in ["rank", "priority", "decision", "segment", "triage", "outlier", "action"]
   )
   ```
   Se consultÃ³ el contrato LLM-generado como fuente primaria (`existing_dec.get("enabled")`), lo cual es correcto, pero mantiene un fallback con keywords. Esto es razonable â€” el CAPABILITY_DETECTION_PROMPT le dice al LLM que setee los flags, y las keywords son fallback para cuando el LLM no los setea.

4. **CAPABILITY_DETECTION_PROMPT aparece duplicado:** Una vez como constante `CAPABILITY_DETECTION_PROMPT` (lÃ­nea ~140) y otra vez inline dentro de `CONTRACT_HARD_RULES` (lÃ­nea ~167). Es redundante.

**Veredicto:** âš ï¸ **Parcialmente correcto.** La direcciÃ³n es buena (LLM como fuente primaria, keywords como fallback), pero los tokens no se eliminaron realmente â€” se reorganizaron. La mejora real es que ahora se consulta el contrato LLM-generado primero, y las keywords son fallback mÃ¡s cortas y genÃ©ricas.

**Riesgo:** ğŸŸ¡ Medio. Las funciones siguen funcionando correctamente, pero el "cero hardcoding" no se logrÃ³ del todo.

---

### âš ï¸ Fase 3: Cleaning Reviewer â€” Gates/regex â€” PARCIAL

**Lo que hizo Claude Code:**
- EliminÃ³ `_FALLBACK_CLEANING_GATES` (6 gates, ~35 lÃ­neas).
- EliminÃ³ `_DEFAULT_ID_REGEX` y `_DEFAULT_PERCENT_REGEX`.
- ReemplazÃ³ con `_GENERIC_ID_REGEX` mÃ¡s corto (sin "partida", "invoice", "account", "plazo").
- `_merge_cleaning_gates()` ahora retorna lista vacÃ­a si no hay gates en el contrato.
- EliminÃ³ `alias_map` de `_normalize_gate_name()`.

**âš ï¸ Problemas detectados:**

1. **`_GENERIC_ID_REGEX` sigue siendo una regex hardcodeada:**
   ```python
   _GENERIC_ID_REGEX = r"(?i)(^id$|(?:_id$)|(?:^id_)|(?:^|[_\W])(?:id|entity|code|key)(?:[_\W]|$))"
   ```
   Es mÃ¡s genÃ©rica que antes (se eliminaron los tokens en espaÃ±ol), pero sigue siendo pattern matching por nombre. La recomendaciÃ³n era usar `column_roles` del contrato como fuente primaria, y solo caer a regex si no hay roles. La implementaciÃ³n actual ya consulta `column_roles` primero (via `_columns_with_role_tokens`), lo cual es correcto, pero la regex genÃ©rica como fallback es aceptable.

2. **`_DEFAULT_PERCENT_REGEX` NO fue reemplazada:** Se eliminÃ³ la constante pero no veo un reemplazo genÃ©rico en el diff. Si alguna funciÃ³n la usaba como regex de fallback para detectar columnas porcentuales, podrÃ­a faltar. Sin embargo, el gate `no_semantic_rescale` que la usaba fue eliminado con los fallback gates, asÃ­ que esto probablemente no es un problema.

3. **La eliminaciÃ³n del `alias_map` puede causar regresiÃ³n funcional:** Antes, variantes como "numeric_parsing_verification" se mapeaban a "numeric_parsing_validation". El test fue actualizado para reflejar esto (`assert _normalize_gate_name("Numeric Parsing Verification") == "numeric_parsing_verification"` en vez de `"numeric_parsing_validation"`). Esto significa que un contrato que genere "numeric_parsing_verification" ya no se reconciliarÃ¡ con gates que esperan "numeric_parsing_validation". **Esto puede causar gate mismatches silenciosos.** Sin embargo, si el contrato V4.1 es la fuente de verdad para los nombres de gates, y tanto el productor como el consumidor usan el mismo nombre, esto deberÃ­a ser consistente.

**Veredicto:** âš ï¸ **Parcialmente correcto.** Las eliminaciones principales son correctas. La regex genÃ©rica es aceptable como fallback despuÃ©s de `column_roles`. La eliminaciÃ³n del alias map es riesgosa pero coherente con la filosofÃ­a de "el contrato es la fuente de verdad".

**Riesgo:** ğŸŸ¡ Medio. Posibles gate mismatches si el LLM genera nombres de gates con variantes que antes se normalizaban.

---

### âš ï¸ Fase 4: QA Reviewer â€” Keywords â€” PARCIAL

**Lo que hizo Claude Code:**
- EliminÃ³ `_REGRESSOR_KEYWORDS` (16 nombres hardcodeados).
- EliminÃ³ `CONTRACT_BROKEN_FALLBACK_GATES`.
- `_looks_like_regressor()` ahora usa convenciÃ³n de nombres + 4 excepciones hardcodeadas.
- `resolve_qa_gates()` retorna lista vacÃ­a si faltan gates.

**âš ï¸ Problemas detectados:**

1. **`_looks_like_regressor` NO es realmente "genÃ©rico por convenciÃ³n":**
   ```python
   if simple.endswith("Regressor"): return True     # âœ… GenÃ©rico
   if simple.lower() in {"svr", "linearsvr"}: ...   # âŒ Hardcodeado
   if simple in {"ElasticNet", "Lasso", "Ridge", "LinearRegression"}: ... # âŒ Hardcodeado
   ```
   Se eliminÃ³ el set de 16 nombres y se reemplazaron con: 1 convenciÃ³n genÃ©rica (`endswith("Regressor")`) + 6 nombres aÃºn hardcodeados. Es una mejora parcial â€” pasÃ³ de 16 a 6 nombres fijos. Sin embargo, Claude Code documentÃ³ por quÃ©: "common regression models inherit RegressorMixin", que es una justificaciÃ³n vÃ¡lida para mantenerlos como excepciones a la convenciÃ³n.

2. **`resolve_qa_gates()` retorna lista vacÃ­a es potencialmente peligroso:** Si no hay gates y retorna `[]`, el QA reviewer no evalÃºa ningÃºn gate. Esto podrÃ­a dejar pasar cÃ³digo sin revisiÃ³n de calidad. La implementaciÃ³n anterior usaba `CONTRACT_BROKEN_FALLBACK_GATES` con `security_sandbox`, `must_read_input_csv`, y `no_synthetic_data` como safety net. Sin estos gates de seguridad, el QA reviewer pierde su Ãºltima lÃ­nea de defensa.

**Veredicto:** âš ï¸ **Parcialmente correcto.** La reducciÃ³n de 16 a 6 nombres en `_looks_like_regressor` es buena direcciÃ³n pero no es "cero hardcoding". La eliminaciÃ³n de `CONTRACT_BROKEN_FALLBACK_GATES` es la mÃ¡s arriesgada â€” deberÃ­a al menos mantener `security_sandbox` como gate incondicional.

**Riesgo:** ğŸŸ¡ Medio. La ausencia de gates de seguridad cuando el contrato falla es un riesgo real.

---

### ğŸ”´ Fase 11: graph.py â€” MÃ³dulos extraÃ­dos â€” INCOMPLETO / CON PROBLEMAS

**Lo que hizo Claude Code:**
CreÃ³ `src/graph/steps/` con 3 mÃ³dulos:
- `contract_resolution.py` (322 lÃ­neas, 7 funciones)
- `context_builders.py` (684 lÃ­neas, 5 funciones pÃºblicas + helpers)
- `result_evaluator.py` (158 lÃ­neas, 3 funciones)

E importÃ³ con aliases en graph.py:
```python
from src.graph.steps.contract_resolution import (
    _resolve_contract_columns as _steps_resolve_contract_columns,
    ...
)
```

**ğŸ”´ PROBLEMAS CRÃTICOS DETECTADOS:**

1. **Las funciones estÃ¡n DUPLICADAS, no EXTRAÃDAS:**
   Las funciones originales **siguen existiendo en `graph.py`** (confirmado: `_resolve_contract_columns` en lÃ­nea 2804, `_build_cleaned_data_summary_min` en lÃ­nea 2455, `_apply_review_consistency_guard` en lÃ­nea 1048, `_harmonize_review_packets_with_final_eval` en lÃ­nea 1098). Claude Code creÃ³ copias en los mÃ³dulos `steps/` pero NO eliminÃ³ los originales de `graph.py`.

2. **Los imports con alias `_steps_*` NUNCA SE USAN:**
   BusquÃ© `_steps_resolve_contract_columns`, `_steps_build_cleaned_data_summary_min`, `_steps_apply_review_consistency_guard`, `_steps_harmonize_review_packets`, `_steps_looks_blocking_retry_signal`, `_steps_build_required_sample_context`, `_steps_build_signal_summary_context` en graph.py. **Ninguno tiene resultados** â€” son imports muertos.

3. **`graph.py` sigue teniendo +21K lÃ­neas:**
   El diff muestra **114 lÃ­neas aÃ±adidas y 0 eliminadas** en graph.py. Las funciones extraÃ­das suman ~1,150 lÃ­neas que deberÃ­an haberse eliminado de graph.py. El archivo NO se redujo.

4. **`_norm_name` existe en 3 copias:**
   - `graph.py` lÃ­nea 265
   - `context_builders.py` lÃ­nea 40
   - `contract_resolution.py` lÃ­nea 19
   
   La definiciÃ³n es idÃ©ntica en las 3, pero esta triplicaciÃ³n es exactamente el anti-patrÃ³n que querÃ­amos eliminar.

5. **El `__init__.py` re-exporta funciones que nadie importa externamente:**
   El archivo `steps/__init__.py` tiene un `__all__` completo pero nadie importa desde `src.graph.steps` directamente â€” graph.py importa directamente desde los sub-mÃ³dulos.

**Veredicto:** ğŸ”´ **Incompleto y con riesgo alto.** Claude Code creÃ³ los mÃ³dulos correctamente (la estructura y el cÃ³digo extraÃ­do son buenos), pero no completÃ³ el trabajo:
- No eliminÃ³ las funciones originales de graph.py.
- No actualizÃ³ las llamadas en graph.py para usar los imports.
- graph.py tiene ahora mÃ¡s cÃ³digo que antes (114 lÃ­neas mÃ¡s).
- El resultado es cÃ³digo duplicado, no cÃ³digo extraÃ­do.

**Â¿Por quÃ© los tests pasan?** Porque graph.py sigue usando sus propias definiciones locales. Los imports muertos no causan errores, solo cÃ³digo innecesario. Los mÃ³dulos en `steps/` son copias funcionales pero no se usan.

**Riesgo:** ğŸ”´ **Alto.** Dos copias de cada funciÃ³n crea un riesgo de divergencia â€” si alguien modifica una versiÃ³n y no la otra, el comportamiento serÃ¡ inconsistente.

---

## ğŸ” HALLAZGOS TRANSVERSALES

### 1. Encoding de comentarios
Los comentarios y banners insertados por Claude Code muestran caracteres Unicode mal renderizados en unicode:
```
# â”€â”€ Token sets removed (seniority refactoring) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```
Se muestra como `Ã”Ã¶Ã‡Ã”Ã¶Ã‡` en el diff, lo que sugiere un problema de encoding. Esto es cosmÃ©tico pero indica que Claude Code usÃ³ caracteres box-drawing UTF-8 que el terminal/git renderizÃ³ con encoding incorrecto.

### 2. PatrÃ³n de "movimiento lateral" en token sets
En las Fases 1, 3, y 4, el patrÃ³n dominante es: eliminar listas de tokens como constantes globales â†’ reintroducirlas como tuplas/sets literales inline o locales. Esto es una mejora de encapsulaciÃ³n pero NO es una eliminaciÃ³n real de hardcoding. La diferencia es que:
- Antes: ~120 tokens en constantes globales visibles y crecientes
- Ahora: ~30 tokens en lÃ­neas inline menos visibles pero aÃºn estÃ¡ticas

### 3. Calidad de la extracciÃ³n de mÃ³dulos
Los 3 archivos en `steps/` estÃ¡n **bien escritos**:
- Docstrings claros
- Tipos correctos
- Imports mÃ­nimos y correctos
- La lÃ³gica es idÃ©ntica a la original en graph.py

El problema NO es la calidad del cÃ³digo extraÃ­do, sino que la extracciÃ³n estÃ¡ incompleta (las originales no se borraron y los call sites no se actualizaron).

---

## ğŸ“Š SCORECARD FINAL

| CategorÃ­a | PuntuaciÃ³n |
|---|---|
| **Correctitud funcional** | 9/10 â€” Tests pasan, no se rompiÃ³ nada |
| **Completitud vs la auditorÃ­a** | 7/10 â€” 8 de 12 fases completamente correctas |
| **Calidad de cÃ³digo nuevo** | 8/10 â€” Bien escrito, buena estructura |
| **EliminaciÃ³n real de hardcoding** | 6/10 â€” Muchos tokens se reorganizaron, no se eliminaron |
| **graph.py desacoplamiento** | 3/10 â€” MÃ³dulos creados pero funciones duplicadas y no usadas |
| **Seguridad del refactoring** | 8/10 â€” Conservador, no rompiÃ³ tests |

---

## âš¡ ACCIONES PENDIENTES (ordenadas por prioridad)

### P0 â€” CrÃ­ticas

1. **Completar la extracciÃ³n de graph.py:**
   - Eliminar las funciones originales de graph.py que ya estÃ¡n en `steps/`
   - Actualizar las llamadas en graph.py para usar los imports de `steps/`
   - O bien: eliminar los imports alias `_steps_*` y usar los nombres originales directamente
   - Eliminar las 2 copias extras de `_norm_name` (mantener solo 1 en un lugar compartido)

2. **Restaurar security_sandbox como gate incondicional en QA:**
   - `resolve_qa_gates()` deberÃ­a mantener al menos `security_sandbox` como gate HARD incluso cuando no hay gates en el contrato. La eliminaciÃ³n de `CONTRACT_BROKEN_FALLBACK_GATES` removiÃ³ un gate de seguridad que deberÃ­a ser incondicional.

### P1 â€” Importantes

3. **Eliminar la duplicaciÃ³n de CAPABILITY_DETECTION_PROMPT** en execution_planner.py (aparece 2 veces).

4. **Considerar mover los tokens inline de `_strategy_mentions_resampling` y `_build_visual_requirements` a queries al contrato LLM-generado**, ya que el CAPABILITY_DETECTION_PROMPT ya le pide al LLM que setee estos flags.

### P2 â€” CosmÃ©ticas

5. **Arreglar encoding de caracteres** en los comentarios banner (caracteres box-drawing â†’ ASCII simple `---` o `===`).

6. **Limpiar los archivos diff temporales** generados durante esta auditorÃ­a.

---

## ğŸ† CONCLUSIÃ“N

Claude Code realizÃ³ un trabajo **sÃ³lido y conservador** â€” priorizÃ³ no romper tests por encima de completitud. Las **8 fases simples** (F2, F6, F7, F8, F9, F10, F12, tests) se implementaron correctamente y con buen criterio. Las **3 fases de eliminaciÃ³n de tokens** (F1, F3, F4) se ejecutaron con una estrategia de "reorganizar y reducir" en vez de "eliminar completamente", lo cual es un compromiso razonable para un refactoring.

El **problema principal** es la **Fase 11 (graph.py):** los mÃ³dulos de steps/ se crearon correctamente pero su integraciÃ³n estÃ¡ incompleta â€” las funciones estÃ¡n duplicadas y los imports no se usan. Esto necesita completarse para que el refactoring tenga efecto real sobre graph.py.

**Score del trabajo de Claude Code: 7.5/10**

Para llegar a 10/10: completar la extracciÃ³n de graph.py y restaurar el gate `security_sandbox` incondicional.
